# Time, Data Cubes {#raster}

<!--
TODO:
refer to
[@appel2019demand]
-->
 
Time information may sometimes be considered an attribute of
a feature, e.g. when we register the year of construction
of a building, or date of birth of a person (chapter
\@ref(featureattributes)). In other cases it may refer to the time
of observing an attribute, or the time for which a prediction of an
attribute has been made. In these cases, time is on equal footing
with space, and time and space together describe the dimensions
over which we observe, model, or make predictions.

One way of considering our world is that of a four-dimensionsal
space, with three space- and one time-dimension. In that view,
events become "things" or "objects" [@galton]. Although such a view
does not align well with how we experience and describe the world,
from a data analytic perspective, four numbers, along with their
reference systems, suffice to describe space and time coordinates
of an observation associated with a point location and time instance.

## Cube dimensions

Phenomena in space and time can be thought of as functions with
domain space and time, and as range the observed attribute. 
For discrete events or objects, the range is typically discrete, and
precise delineation involves describes the precise coordinates
where it starts or stops, which may result in a vector geometry.
For continuous phenomena, there are infinitely many values to
represent and the most common approach is to discretize space and
time regularly over the domain extent of interest. This leads to
a number of familiar data structures:

* time series, depicted as time lines for functions of time
* images or raster data for two-dimensional spatial data
* sequences of images for dynamic spatial data

The third form of this, where a variable $Z$ depends on $x$, $y$
and $t$, as in

$$Z = f(x, y, t)$$

is the archetype of a spatiotemporal array or _data cube_: the shape
of the volume where points regularly discretizing the domain forms a
cube. We call the variables that form the range (here: $x, y, t$) the
cube _dimensions_.  Data cubes may have multiple attributes, as in

$$\{Z_1,Z_2,...,Z_p\} = f(x, y, t)$$

and if $Z$ is functional, e.g. reflectance values measured over
the electromagnetic spectrum, the spectral wavelengths $\lambda$
may form an additional dimension, as in $Z = f(x,y,t,\lambda)$.
Multiple time dimensions arise when making forecasts for different
times in the future $t'$ at different times $t$.

Here, we will consider any dataset with one or more space dimensions
and zero or more time dimensions a data cubes. That includes

* time series for sets of features,
* raster data, 
* multi-spectral raster data (images), or
* time series of multi-spectral raster data (video)

Data cubes are usually stored in multi-dimensional arrays, and the
usual relationship between 1-based array index $i$ and an associated
dimension variable $x$

$$x = o_x + (i-1) d_x$$

with $o_x$ the origin and $d_x$ the grid spacing of this dimension.

For more general cases like those in figure
\@ref(fig:rastertypes01)b-c, the relation between $x$ and $y$
and array indexes $i$ and $j$ is

$$x = o_x + (i-1) d_x + (j-1) a_1$$
    
$$y = o_y + (i-1) a_2 + (j-1) d_y$$

With two affine parameters $a_1$ and $a_2$; this is the so-called
_geotransform_ as used in GDAL.  When $a_1=a_2=0$, this
reduces to the regular raster of figure \@ref(fig:rastertypes01)a.
For integer indexes, the coordinates are that of the starting _edge_
of a grid cell. For most common imagery formats, $d_y$ is negative,
indicating that image row index increases with decreasing $y$
values (southward).  To get coordinates of the grid cell center of
the top left grid cell (in case of a negative $d_y$), use $i=1.5$
and $j=1.5$. 

For rectilinear rasters, a table that maps array index to dimension
values is needed. NetCDF files for instance document the values
of spatial dimension variables that correspond to the center of
spatial grid cells, as they would be understood by GDAL.

For curvilinear rasters an array that maps every combinations of
$i,j$ into $x,y$ pairs is needed, or a parametric function that
does this (e.g. a projection).

## Support of the time dimensions

Section \@ref(agr) discussed _spatial_ support of attribute
variables, but the same notion applies to time. Although time is
rarely reported by explicit time periods having a start- en end-time,
in many cases either the time stamp implies a period (e.g. 2021 a
year, 2021-01 a month) or the time period is taken as the period
from the time stamp of the current record up to but not including
the time stamp of the next record.

An example is MODIS satellite imagery, where vegetation indexes (NDVI
and EVI) are available as 16-day composites. Sentinel-2 or Landsat-8
data on the other hand are "snapshot" images, and have revisit times
of 5 and 16 days respectively. When temporally aggregating the latter
one would select all images falling in the target time interval;
when aggregating the MODIS 16-day composite, one might weigh images
according to the overlap of the 16-day period and the target period.

## Raster data cubes

As introduced in section \@ref(coverages), raster data are spatial
datasets where observations are aligned on a regular grid usually
with square grid cells (in some coordinate reference system, chapter
\@ref(cs)). Raster datasets are used often to represent spatially
continuously varying phenomena such as temperature or elevation,
and arise both from observation (e.g., satellite imagery) or by
modelling (weather data, interpolated maps, density esimates).

## Vector data cubes {#datacubes}

Data cubes are multi-dimensional array data, where array dimensions
are meaningfully related to categorical or continuous variables
that may include space and time [@lu2018multidimensional]. We have
seen raster data cubes so far, e.g.

* raster data naturally fit in two-dimensional arrays, 
* multi-spectral raster data fit in three-dimensional arrays (cubes), and 
* time series of multi-spectral raster data fit in four-dimensional arrays (hyper-cubes).

Besides Earth Observation/satellite imagery data, a large class
of data cubes come from modelling data, e.g. from oceanographic,
meteorologic or climate models, where dimensions may include

* latitude and longitude
* altitude, or depth
* pressure level (substituting altitude)
* time 
* time to forecast, in addition to time when a forecast was made

we can add to this as an additional dimension

* variable of interest (pressure, temperature, humidity, wind speed, salinity, ...)

when we accept that categorical variables also "take" a
dimension. The alternative would be to consider these as "fields",
or "attributes" of array records. Being able to swap dimensions to
attributes flexibly and vice-versa leads to powerful analysis, as
e.g. shown by the powerful array database SciDB [@brown2010overview].

We go from raster data cubes to _vector data cubes_ if we replace
the two or three raster dimensions with one dimension listing a set
of feature geometries (points, lines or polygons). One example would
be air quality data, where we could have $PM_{10}$ measurements for

* a set of monitoring stations, and
* a sequence of time intervals

aligned in a vector data cube.  Another example would be demographic
or epidemiological data, where we have a time series of (population,
disease) counts, with number of persons

* by region, for $n$ regions
* by age class, for $m$ age classes, and
* by year, for $p$ years.

which forms an array with $n m p$ elements. 

Thinking along the classical GIS lines, where we would have either
raster or vector data, one is left with the question what to do
when we have a raster time series data cube (e.g.  a climate model
forecast) and want to obtain a vector time series data cube with
aggregates of the model forecast over polygons, as time series.
For spatial data science, support of vector and raster data cubes
is extremely useful, because many variables are both spatially
and temporaly varying, and because we often want to either change
dimensions or aggregate them out, but in a fully flexible manner
and order. Examples of changing dimensions are

* interpolating air quality measurements to values on a regular grid (raster)
* estimating density maps from points or lines, e.g. with the number of flights passing by per week within a range of 1 km
* aggregating climate model predictions to summary indicators for administrative regions
* combining Earth observation data from different sensors, e.g. Modis (250 m pixels, every 16 days) with Sentinel-2 (10 m,
every 5 days).

Examples of aggregating one ore more full dimensions are assessments of

* which air quality monitoring stations indicate unhealthy conditions
* which region has the highest increase in disease incidence
* global warming (e.g. in degrees per year)

## Exercises 

1. NDVI, normalized differenced vegetation index, is coputed as (NIR-R)/(NIR+R), with NIR the near infrared and R the red band.  Read the `L7_ETMs.tif` file into object `x`, and distribute the band dimensions over attributes by `split(x, "band")`. Then, compute NDVI by using an expression that uses the NIR (band 4) and R (band 3) attributes directly.
1. Compute NDVI for the S2 image, using `st_apply` and an a function `ndvi = function(x) (x[4]-x[3])/(x[4]+x[3])`. Plot the result, and write the result to a GeoTIFF. Explain the difference in runtime between plotting and writing.
1. Use `st_transform` to transform the `stars` object read from `L7_ETMs.tif` to EPSG 4326. Print the object. Is this a regular grid? Plot the first band using arguments `axes=TRUE` and `border=NA`, and explain why this takes such a long time.
1. Use `st_warp` to warp the `L7_ETMs.tif` object to EPSG 4326, and plot the resulting object with `axes=TRUE`. Why is the plot created much faster than after `st_transform`?
