[
["index.html", "Spatial Data Science with R Preface", " Spatial Data Science with R Edzer Pebesma, Roger Bivand 2018-05-09 Preface "],
["intro.html", "Chapter 1 Getting Started 1.1 A first map 1.2 Reading and writing 1.3 Exercises", " Chapter 1 Getting Started This chapter gives a quick start to get you going with spatial data science with R. It is easier to read when understanding R at the level of, say, R for Data Science (Wickham and Grolemund 2017). 1.1 A first map There is a lot to say about spatial data, but let us first create a map. We can create a simple map by: library(tidyverse) library(sf) system.file(&quot;gpkg/nc.gpkg&quot;, package=&quot;sf&quot;) %&gt;% read_sf() %&gt;% st_transform(32119) %&gt;% select(BIR74) %&gt;% plot(graticule = TRUE, axes = TRUE) Figure 1.1: a first map A lot went on, here. We will describe the steps in detail. First, we loaded two R packages: library(tidyverse) library(sf) where tidyverse is needed for the tidyverse functions and methods, and sf is needed for the spatial commands and spatial tidyverse methods. Package sf implements simple features, a standardised way to encode polygon data (points, lines, polygons). We will say more about simple features in chapter 3. Most commands in package sf start with st_, short for spatiotemporal, a convention it shares with e.g. PostGIS. The %&gt;% (pipe) symbols should be read as then: we read a %&gt;% b() %&gt;% c() %&gt;% d(n = 10) as a then b then c then d, and that is just alternative syntax for d(c(b(a)), n = 10) or tmp1 &lt;- b(a) tmp2 &lt;- c(tmp1) tmp3 &lt;- d(tmp2, n = 10) The pipe form is easier to read because we don’t have to go from right to left, and avoids the need to choose names for intermediate results. For the illustration we picked a data file that comes with sf, the location of which depends on the operating system used: (file &lt;- system.file(&quot;gpkg/nc.gpkg&quot;, package=&quot;sf&quot;)) #&gt; [1] &quot;/home/edzer/R/x86_64-pc-linux-gnu-library/3.4/sf/gpkg/nc.gpkg&quot; Never use system.file if you want to read your own data; in that case, fname should be the data source (typically file) name (section 1.2). (Parens around this expression are used to have the result not only stored, but also printed.) Then, we read this file into R using read_sf: (nc &lt;- read_sf(file)) #&gt; Simple feature collection with 100 features and 14 fields #&gt; geometry type: MULTIPOLYGON #&gt; dimension: XY #&gt; bbox: xmin: -84.3 ymin: 33.9 xmax: -75.5 ymax: 36.6 #&gt; epsg (SRID): 4267 #&gt; proj4string: +proj=longlat +datum=NAD27 +no_defs #&gt; # A tibble: 100 x 15 #&gt; AREA PERIMETER CNTY_ CNTY_ID NAME FIPS FIPSNO CRESS_ID BIR74 SID74 #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0.114 1.44 1825 1825 Ashe 37009 37009 5 1091 1.00 #&gt; 2 0.0610 1.23 1827 1827 Allegh… 37005 37005 3 487 0 #&gt; 3 0.143 1.63 1828 1828 Surry 37171 37171 86 3188 5.00 #&gt; 4 0.0700 2.97 1831 1831 Currit… 37053 37053 27 508 1.00 #&gt; 5 0.153 2.21 1832 1832 Northa… 37131 37131 66 1421 9.00 #&gt; 6 0.0970 1.67 1833 1833 Hertfo… 37091 37091 46 1452 7.00 #&gt; # ... with 94 more rows, and 5 more variables: NWBIR74 &lt;dbl&gt;, BIR79 &lt;dbl&gt;, #&gt; # SID79 &lt;dbl&gt;, NWBIR79 &lt;dbl&gt;, geom &lt;MULTIPOLYGON [°]&gt; which creates a “spatial tibble”: class(nc) #&gt; [1] &quot;sf&quot; &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; This object is transformed into a new coordinate reference system (North Carolina State Plane, with EPSG code 32119): (nc.32119 &lt;- st_transform(nc, 32119)) #&gt; Simple feature collection with 100 features and 14 fields #&gt; geometry type: MULTIPOLYGON #&gt; dimension: XY #&gt; bbox: xmin: 124000 ymin: 14700 xmax: 931000 ymax: 318000 #&gt; epsg (SRID): 32119 #&gt; proj4string: +proj=lcc +lat_1=36.16666666666666 +lat_2=34.33333333333334 +lat_0=33.75 +lon_0=-79 +x_0=609601.22 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #&gt; # A tibble: 100 x 15 #&gt; AREA PERIMETER CNTY_ CNTY_ID NAME FIPS FIPSNO CRESS_ID BIR74 SID74 #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0.114 1.44 1825 1825 Ashe 37009 37009 5 1091 1.00 #&gt; 2 0.0610 1.23 1827 1827 Allegh… 37005 37005 3 487 0 #&gt; 3 0.143 1.63 1828 1828 Surry 37171 37171 86 3188 5.00 #&gt; 4 0.0700 2.97 1831 1831 Currit… 37053 37053 27 508 1.00 #&gt; 5 0.153 2.21 1832 1832 Northa… 37131 37131 66 1421 9.00 #&gt; 6 0.0970 1.67 1833 1833 Hertfo… 37091 37091 46 1452 7.00 #&gt; # ... with 94 more rows, and 5 more variables: NWBIR74 &lt;dbl&gt;, BIR79 &lt;dbl&gt;, #&gt; # SID79 &lt;dbl&gt;, NWBIR79 &lt;dbl&gt;, geom &lt;MULTIPOLYGON [m]&gt; and a single attribute column is selected (nc.32119.bir74 &lt;- select(nc.32119, BIR74)) #&gt; Simple feature collection with 100 features and 1 field #&gt; geometry type: MULTIPOLYGON #&gt; dimension: XY #&gt; bbox: xmin: 124000 ymin: 14700 xmax: 931000 ymax: 318000 #&gt; epsg (SRID): 32119 #&gt; proj4string: +proj=lcc +lat_1=36.16666666666666 +lat_2=34.33333333333334 +lat_0=33.75 +lon_0=-79 +x_0=609601.22 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #&gt; # A tibble: 100 x 2 #&gt; BIR74 geom #&gt; &lt;dbl&gt; &lt;MULTIPOLYGON [m]&gt; #&gt; 1 1091 (((387345 278387, 381334 282774, 379438 282943, 373250 290553, 36… #&gt; 2 487 (((408602 292425, 408565 293985, 406643 296873, 406420 3e+05, 402… #&gt; 3 3188 (((478717 277490, 476936 278867, 471503 279173, 470806 281394, 46… #&gt; 4 508 (((878194 289128, 877381 291117, 875994 290881, 874941 292805, 87… #&gt; 5 1421 (((769835 277796, 768364 274842, 762616 274401, 763168 269009, 76… #&gt; 6 1452 (((812328 277876, 791158 277012, 789882 277579, 777724 277107, 76… #&gt; # ... with 94 more rows Finally, the result is plotted, with the command: plot(nc.32119.bir74, graticule = TRUE, axes = TRUE) as shown in figure 1.1. Where do these commands come from? library and system.file are base R. We can ask for help about a particular command by entering e.g. ?library The command read_sf is an alternative to the st_read, which returns a spatial tibble instead of a spatial data frame, and will be discussed in section 1.2. The st_transform method is used here to convert from the geographic coordinates (degrees longitude and latitude) into “flat” coordinates, meaning \\(x\\) and \\(y\\) coordinates in a planar system. It will be discussed in section 7.2. The plot method for sf objects chooses default colors and legends settings; we instructed it to add a graticule (the grey lines of equal longitude and latitude) and degree labels along the axes. It is described in chapter 9. As witnessed by the plot, the plot command receives county polygons as well as BIR74 values for each polygon. How is it possible that we select only the BIR74 variable, but still can plot the polygons? This is because package sf provides a select method: methods(select) #&gt; [1] select.data.frame* select.default* select.grouped_df* #&gt; [4] select.list select.sf select.tbl_cube* #&gt; see &#39;?methods&#39; for accessing help and source code and this method (select.sf) makes the geometry (geom) sticky: nc %&gt;% select(BIR74) %&gt;% names() #&gt; [1] &quot;BIR74&quot; &quot;geom&quot; We get the “normal” select behaviour if we first coerce to a normal tibble: nc %&gt;% as_tibble(validate = TRUE) %&gt;% select(BIR74) %&gt;% names() #&gt; [1] &quot;BIR74&quot; A ggplot is created when we use geom_sf: ggplot() + geom_sf(data = nc.32119) + aes(fill = BIR74) + theme(panel.grid.major = element_line(color = &quot;white&quot;)) + scale_fill_gradientn(colors = sf.colors(20)) and a facet plot for a pair of columns in nc.32119 is obtained by gathering the columns: nc2 &lt;- nc.32119 %&gt;% select(SID74, SID79) %&gt;% gather(VAR, SID, -geom) ggplot() + geom_sf(data = nc2, aes(fill = SID)) + facet_wrap(~VAR, ncol = 1) + scale_y_continuous(breaks = 34:36) + scale_fill_gradientn(colors = sf.colors(20)) + theme(panel.grid.major = element_line(color = &quot;white&quot;)) An interactive, leaflet-type map is obtained by suppressPackageStartupMessages(library(mapview)) #nc.32119 %&gt;% mapview(zcol = &quot;BIR74&quot;, legend = TRUE, col.regions = sf.colors) 1.2 Reading and writing Typical R data science tasks start with reading data from an external source; this may be a file, or a set of files like a “shapefile”, or a database, or a web service. Package sf can read from a large number of different data sources; the following command shows how many nrow(st_drivers(&quot;vector&quot;)) # vector drivers #&gt; [1] 80 nrow(st_drivers(&quot;raster&quot;)) # raster drivers #&gt; [1] 136 (the output you see may differ because of different operating system and configuration.) 1.2.1 GDAL st_drivers lists the drivers available to GDAL, the geospatial data abstraction library. This library can be seen as the swiss army knive of spatial data; besides for R it is used in Python, QGIS, PostGIS, and more than 100 other software projects. The dependency of sf on other R libraries and system libraries is shown in figure 1.2. Figure 1.2: sf and its dependencies Note that the C/C++ libraries used (GDAL, GEOS, Proj, liblwgeom, udunits2) are all developed, maintained and used by (data) science communities that are much larger than the R community. By using these libraries, we share how we understand what we are doing with all the other communities that use these libraries. This is not only important for resolving problems, but also for establishing which findings are facts. GDAL is a “library of libraries” – in order to read all these data sources it needs a large number of other libraries. It typically links to over 100 other libraries. Binary packages distributed by CRAN contain only statically linked code: CRAN does not want to make any assumptions about presence of third-party libraries on the host system. As a consequence, when the binary sf package is installed from CRAN, it includes a copy of all the required external libraries as well as their dependencies, which may amount to 50 or 100 Mb. 1.2.2 st_read or read_sf? The function to read vector data is st_read. Function read_sf is largely the same as `st_read, but chooses a few tidyverse-style defaults: it is silent by default, where st_read gives a short report it returns a spatial tibble instead of a spatial data frame it sets as default stringsAsFactors = FALSE, where st_read listens to the global option default.stringsAsFactors() (which is TRUE by default) In the same fashion, compared to st_write write_sf, is also silent overwrites layers (i.e., sets delete_layer = TRUE) by default, which st_write does not do. (TBD: reading and writing raster data) 1.2.3 Getting help 1.2.4 Reading from files, and shapefiles We saw above that a spatial dataset can be read from a single file by nc &lt;- system.file(&quot;gpkg/nc.gpkg&quot;, package=&quot;sf&quot;) %&gt;% read_sf() In some cases, spatial datasets are contained in multiple files, e.g. in the case of shapefiles. A “shapefile” should be really understood as a set of files with a common prefix, or even a directory with several of such sets. Package sf comes with a couple of shapefiles packaged, a directory listing of the shape directory in the packge is obtained by list.files(system.file(&quot;shape/&quot;, package = &quot;sf&quot;)) #&gt; [1] &quot;nc.dbf&quot; &quot;nc.prj&quot; #&gt; [3] &quot;nc.shp&quot; &quot;nc.shx&quot; #&gt; [5] &quot;storms_xyz_feature.dbf&quot; &quot;storms_xyz_feature.shp&quot; #&gt; [7] &quot;storms_xyz_feature.shx&quot; &quot;storms_xyz.dbf&quot; #&gt; [9] &quot;storms_xyz.shp&quot; &quot;storms_xyz.shx&quot; #&gt; [11] &quot;storms_xyzm_feature.dbf&quot; &quot;storms_xyzm_feature.shp&quot; #&gt; [13] &quot;storms_xyzm_feature.shx&quot; &quot;storms_xyzm.dbf&quot; #&gt; [15] &quot;storms_xyzm.shp&quot; &quot;storms_xyzm.shx&quot; We can read a single shapefile by nc &lt;- system.file(&quot;shape/nc.shp&quot;, package=&quot;sf&quot;) %&gt;% read_sf() and it is important to know that in that case all four files starting with nc are read from this directory. We can also read the directory with shapfiles by something &lt;- system.file(&quot;shape&quot;, package=&quot;sf&quot;) %&gt;% read_sf() #&gt; Warning in evalq((function (..., call. = TRUE, immediate. = FALSE, #&gt; noBreaks. = FALSE, : automatically selected the first layer in a data #&gt; source containing more than one. but we see some warnings now, indicating that we are reading only the first layer from a multi-layer dataset (and not nc.shp!). Indeed, this directory contains multiple layers, which can be queried by system.file(&quot;shape&quot;, package=&quot;sf&quot;) %&gt;% st_layers() #&gt; Driver: ESRI Shapefile #&gt; Available layers: #&gt; layer_name geometry_type features fields #&gt; 1 storms_xyzm_feature Measured Line String 71 1 #&gt; 2 storms_xyz_feature 3D Line String 71 1 #&gt; 3 storms_xyzm Measured Line String 71 0 #&gt; 4 storms_xyz 3D Line String 71 0 #&gt; 5 nc Polygon 100 14 From this list, we could pick one, and use it as the layer argument, as in dataset &lt;- system.file(&quot;shape&quot;, package=&quot;sf&quot;) layer &lt;- &quot;nc&quot; nc &lt;- read_sf(dataset, layer) which is essentially a convoluted way of what we did before to read nc.shp. Considering shapefiles in directories as layers in a dataset is not something that sf came up with, but is the way GDAL handles this. Although it is a good idea in general to give up using shapefiles, we cannot always control the format of the spatial data we get to start with. 1.2.5 Reading from a text string In the special case of a GeoJSON (Butler et al. 2016) dataset, when the dataset is contained in a length-one character vector, it can be directly passed to read_sf and read from memory: str &lt;- &#39;{ &quot;type&quot;: &quot;FeatureCollection&quot;, &quot;features&quot;: [ { &quot;type&quot;: &quot;Feature&quot;, &quot;geometry&quot;: { &quot;type&quot;: &quot;Point&quot;, &quot;coordinates&quot;: [102.0, 0.5] }, &quot;properties&quot;: { &quot;prop0&quot;: &quot;value0&quot; } }, { &quot;type&quot;: &quot;Feature&quot;, &quot;geometry&quot;: { &quot;type&quot;: &quot;LineString&quot;, &quot;coordinates&quot;: [ [102.0, 0.0], [103.0, 1.0], [104.0, 0.0], [105.0, 1.0] ] }, &quot;properties&quot;: { &quot;prop0&quot;: &quot;value0&quot;, &quot;prop1&quot;: 0.0 } }, { &quot;type&quot;: &quot;Feature&quot;, &quot;geometry&quot;: { &quot;type&quot;: &quot;Polygon&quot;, &quot;coordinates&quot;: [ [ [100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0], [100.0, 0.0] ] ] }, &quot;properties&quot;: { &quot;prop0&quot;: &quot;value0&quot;, &quot;prop1&quot;: { &quot;this&quot;: &quot;that&quot; } } } ] }&#39; (sf_obj &lt;- read_sf(str)) #&gt; Simple feature collection with 3 features and 2 fields #&gt; geometry type: GEOMETRY #&gt; dimension: XY #&gt; bbox: xmin: 100 ymin: 0 xmax: 105 ymax: 1 #&gt; epsg (SRID): 4326 #&gt; proj4string: +proj=longlat +datum=WGS84 +no_defs #&gt; # A tibble: 3 x 3 #&gt; prop0 prop1 geometry #&gt; &lt;chr&gt; &lt;chr&gt; &lt;GEOMETRY [°]&gt; #&gt; 1 value0 &lt;NA&gt; POINT (102 0.5) #&gt; 2 value0 0.0 LINESTRING (102 0, 103 1, 104 0, 105 1) #&gt; 3 value0 &quot;{ \\&quot;this\\&quot;: \\&quot;that\\&quot; }&quot; POLYGON ((100 0, 101 0, 101 1, 100 1, 1… 1.2.6 Database reading and writing databases 1.3 Exercises Read the shapefile storms_xyz_feature from the shape directory in the sf package Copy this file to another directory on your computer, and read it from there (note: a shapefile consists of more than one file!) How many features does this dataset contain? Plot the dataset, with axes = TRUE (hint: before plotting, pipe through st_zm to drop Z and M coordinates; more about this in chapter 3). Before plotting, pipe the dataset through st_set_crs(4326). What is different in the plot obtained? References "],
["spaces-1-2-and-3-dimensional-spherical-time-bounded-spaces.html", "Chapter 2 Spaces: 1, 2 and 3-dimensional, spherical, time, bounded spaces", " Chapter 2 Spaces: 1, 2 and 3-dimensional, spherical, time, bounded spaces discusses spaces bounded: water, rivers, road networks "],
["geometries.html", "Chapter 3 Geometries", " Chapter 3 Geometries vertices, edges, lines, polygons, simple features; raster cells "],
["vectorraster.html", "Chapter 4 Vector/Raster", " Chapter 4 Vector/Raster differences, correspondence; properties of rasters; arrays "],
["geometric-manipulations-geometries.html", "Chapter 5 Geometric Manipulations {geometries} 5.1 Unary Operations 5.2 Binary Operations 5.3 N-ary Operations 5.4 Warnings for longitude/latitude geometries", " Chapter 5 Geometric Manipulations {geometries} Simple feature geometries can be queried for properties, combined into new geometries, and combinations of geometries can be queried for properties. This chapter will give an overview of the operations offered by sf. We can categorise operations in terms of what they take as input, and what they give as output. In terms of input we have operations that take a single geometry (unary operations) a pair of geometries (binary operations) a set of geometries (n-ary operations) and in terms of what is returned, we distinguish predicates, returning a logical asserting a certain property is TRUE measures, returning a numeric value (possibly with measurement unit) operations that return a new geometry, or a set of geometries We will now go through all combinations. 5.1 Unary Operations 5.1.1 Unary predicates st_is_simple st_is_valid st_is_longlat st_is == != : st_equals 5.1.2 Unary measures st_dimension st_area st_length st_geohash st_geometry_type 5.1.3 Unary operations returning a geometry st_centroid st_buffer st_jitter st_wrap_dateline st_boundary st_convex_hull st_line_merge merges, on a per-feature basis, connecting LINESTRING elements of a MULTILINESTRING into longer LINESTRINGs. st_make_valid st_node st_point_on_surface st_polygonize st_segmentize st_simplify lwgeom::st_split st_transform st_triangulate st_voronoi st_zm st_collection_extract st_cast Ops: + - (unary, binary) Ops: * / (sfg, Matrix) 5.2 Binary Operations 5.2.1 Binary predicates st_contains st_contains_properly st_covered_by st_covers st_crosses st_disjoint st_equals st_equals_exact st_intersects st_is_within_distance st_within st_touches st_overlaps 5.2.2 Binary measures st_distance st_relate 5.2.3 Binary operations returning a geometry st_intersection &amp; st_union | st_difference ‘/’ st_sym_differenc ‘%/%’ 5.3 N-ary Operations 5.3.1 N-ary operations returning a geometry For n-ary operations, we have only two, n-ary st_intersection and st_difference, which both return geometries, in case of st_intersection along with some properties for each of the geometry. st_make_grid st_graticule 5.4 Warnings for longitude/latitude geometries In st_centroid.sfc(st_geometry(x), of_largest_polygon = of_largest_polygon) : st_centroid does not give correct centroids for longitude/latitude data How serious is this? "],
["attributes.html", "Chapter 6 Attributes 6.1 Attribute-geometry relationship 6.2 Spatially intensive and extensive variables", " Chapter 6 Attributes Feature attributes refer to the properties of features (“things”) that do not describe the feature’s geometry. Feature attributes can be derived from geometry (e.g. lenght of a LINESTRING, area of a POLYGON) but they can also refer to completely different properties, such as the name of a street or a county, the number of people living in a country, the type of a road the soil type in a polygon from a soil map. the opening hours of a shop Although we believe that temporal properties of features are at no less fundamental than their spatial properties, the simple feature access standard and consequently the sf package does not give time a similar role as space; more on that in chapter 21. Most sf objects will contain both geometries and attributes for features. The geometric operations described in the previous chapter @ref{geometries} operate on geometries only. When applied to an object of class sf, all unary operations will, for functions returning a predicate or a measure, ignore all attributes a geometr y, replace the object’s geometry. In all these cases, attribute values remain unmodified. At first sight, that looks rather harmless. But if we look into a simple case of replacing a county boundary with a county centroid, as in library(sf) library(dplyr) system.file(&quot;gpkg/nc.gpkg&quot;, package=&quot;sf&quot;) %&gt;% read_sf() %&gt;% st_transform(32119) %&gt;% select(BIR74, SID74, NAME) %&gt;% st_centroid() %&gt;% head(n = 1) #&gt; Warning in st_centroid.sf(.): st_centroid assumes attributes are constant #&gt; over geometries of x #&gt; Simple feature collection with 1 feature and 3 fields #&gt; geometry type: POINT #&gt; dimension: XY #&gt; bbox: xmin: 386000 ymin: 3e+05 xmax: 386000 ymax: 3e+05 #&gt; epsg (SRID): 32119 #&gt; proj4string: +proj=lcc +lat_1=36.16666666666666 +lat_2=34.33333333333334 +lat_0=33.75 +lon_0=-79 +x_0=609601.22 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #&gt; # A tibble: 1 x 4 #&gt; BIR74 SID74 NAME geom #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;POINT [m]&gt; #&gt; 1 1091 1 Ashe (385605 3e+05) we receive a warning. This warning is justified for the first two variables shown (total births and number of SID disease cases, 1974) which, as such, are not associated with a feature whose geometry is POINT (385605.4 300303.5). The third variable, NAME is however still the county name for the point indicated, but the point geometry no longer is the county geometry. 6.1 Attribute-geometry relationship Changing the feature geometry without changing the feature attributes does change the feature, since the feature is characterised by the combination of geometry and attributes. Can we, ahead of time, predict whether the resulting feature will still meaningfully represent the data when we for instance replaced all geometries with their convex hull or centroid? It depends. Take the example of a road, represented by a LINESTRING, and its attribute property road width. What then is the road width of an arbitray subsectin of this road? That depends on whether the attribute road length describes, for instance the road width everywhere, i.e. road width is constant along the road, or whether it describes an aggregate property, such as minimum road width. In case of the latter, for an arbitrary subsection of the road one could still argue that the minimum road with must be at least as large as the minimum road width for the whole segment, but it is no longer the minimum for that subsection. This gives us two “types” for the attribute-geometry relationship (AGR) constant the attribute value is valid everywhere in or over the geometry aggregate the attribute is an aggregate, a summary value over the geometry For polygon data, typical examples of constant AGR are land use for a land use polygon rock units or geologic strata in a geological map soil type in a soil map elevation class in a elevation map that shows elevation as classes klimate zone in a climate zone map Typical examples for the aggregate AGR are population, either as number of persons or as population density other socio-economic data, summarised by area total emission of pollutants by region A third type of AGR is that where an attribute identifies a feature geometry. The example above is county NAME: the name identifies the county, and is still the county NAME for any sub-area. For an arbitrary sub-area, it is however loses the identity property but becomes a constant attribute. The example is: any point inside a county has still the same county name, but does not longer represent the geometry of that county. We can specify the AGR of an attribute in an sf object by st_set_agr: nc &lt;- system.file(&quot;gpkg/nc.gpkg&quot;, package=&quot;sf&quot;) %&gt;% read_sf() %&gt;% st_transform(32119) nc1 &lt;- nc %&gt;% select(BIR74, SID74, NAME) %&gt;% st_set_agr(c(BIR74 = &quot;aggregate&quot;, SID74 = &quot;aggregate&quot;, NAME = &quot;identity&quot;)) This helps to get rid of warnings that a particular attribute is assumed to be constant over a geometry, if it already is. The following no longer generates a warning nc1 %&gt;% select(NAME) %&gt;% st_centroid() %&gt;% head(1) #&gt; Simple feature collection with 1 feature and 1 field #&gt; Attribute-geometry relationship: 1 constant, 0 aggregate, 0 identity #&gt; geometry type: POINT #&gt; dimension: XY #&gt; bbox: xmin: 386000 ymin: 3e+05 xmax: 386000 ymax: 3e+05 #&gt; epsg (SRID): 32119 #&gt; proj4string: +proj=lcc +lat_1=36.16666666666666 +lat_2=34.33333333333334 +lat_0=33.75 +lon_0=-79 +x_0=609601.22 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs #&gt; # A tibble: 1 x 2 #&gt; NAME geom #&gt; &lt;chr&gt; &lt;POINT [m]&gt; #&gt; 1 Ashe (385605 3e+05) and also changes AGR for NAME from identity to constant when replacing the geometry with the geometry’s centroid: nc1 %&gt;% select(NAME) %&gt;% st_centroid() %&gt;% st_agr() #&gt; NAME #&gt; constant #&gt; Levels: constant aggregate identity 6.2 Spatially intensive and extensive variables "],
["reference-systems.html", "Chapter 7 Reference Systems 7.1 Units of measurement 7.2 Coordinate transformation and conversion", " Chapter 7 Reference Systems Units of measure, reference systems, coordinate transformation and conversion 7.1 Units of measurement Measurement units: (Hand 2004); quantities (David Flater 2018), (D. Flater 2016) 7.2 Coordinate transformation and conversion Geodesics: (Karney 2013) References "],
["plotting-spatial-data.html", "Chapter 8 Plotting spatial data", " Chapter 8 Plotting spatial data Plotting of lines, symbols, polygons (choroplets; overlapping polygons), rasters using color "],
["plot.html", "Chapter 9 Base Plot", " Chapter 9 Base Plot "],
["ggplot2.html", "Chapter 10 ggplot2", " Chapter 10 ggplot2 geom_sf examples; useful annotations and manipulations "],
["interactive-maps.html", "Chapter 11 Interactive Maps", " Chapter 11 Interactive Maps base plot: identify, locator leaflet, tmap, mapview mapedit? "],
["summarizing-geometries.html", "Chapter 12 Summarizing Geometries", " Chapter 12 Summarizing Geometries Properties: dimension, length, area, etc, if not earlier in Ch 3? counts, density, intensity (units; meaningful) "],
["point-pattern-analysis.html", "Chapter 13 Point Pattern Analysis", " Chapter 13 Point Pattern Analysis Basics PP, beyond counting; basic steps in PPA sf - spatstat interface; rasters; "],
["manipulating-attributes-summarise-aggregate-union-sample.html", "Chapter 14 Manipulating attributes: summarise, aggregate, union, sample", " Chapter 14 Manipulating attributes: summarise, aggregate, union, sample "],
["units-of-measure-revisited-attribute-units-intensive-and-extensive-variables.html", "Chapter 15 Units of measure revisited: attribute units, intensive and extensive variables", " Chapter 15 Units of measure revisited: attribute units, intensive and extensive variables "],
["up-and-downscaling.html", "Chapter 16 Up- and Downscaling", " Chapter 16 Up- and Downscaling sampling largest sub-geometry area-weighted interpolation "],
["spatial-interpolation-and-geostatistics.html", "Chapter 17 Spatial Interpolation and geostatistics", " Chapter 17 Spatial Interpolation and geostatistics intro ; variograms; gstat (needs to be sf-ed) "],
["area-data-and-spatial-correlation.html", "Chapter 18 Area Data and Spatial Correlation", " Chapter 18 Area Data and Spatial Correlation spdep stuff "],
["spatial-regression-and-autocorrelation.html", "Chapter 19 Spatial Regression and Autocorrelation", " Chapter 19 Spatial Regression and Autocorrelation intro; "],
["raster-modelling.html", "Chapter 20 Raster Modelling", " Chapter 20 Raster Modelling map algebra; ABM; SDM; Robert’s book. "],
["array.html", "Chapter 21 Array data: raster and vector data cubes", " Chapter 21 Array data: raster and vector data cubes "],
["movement-data.html", "Chapter 22 Movement data", " Chapter 22 Movement data "],
["statistical-modelling-of-spatiotemporal-data.html", "Chapter 23 Statistical modelling of spatiotemporal data", " Chapter 23 Statistical modelling of spatiotemporal data "],
["scalability.html", "Chapter 24 Scalability", " Chapter 24 Scalability "],
["r-data-structures.html", "R data structures 24.1 Homogeneous vectors 24.2 Heterogeneous vectors: list 24.3 Attributes 24.4 various names attributes 24.5 using structure", " R data structures This chapter provides some minimal set of R basics that may make it easier to read this book. A more comprehensive book on R basics is given in (Wickham 2014), chapter 2. As pointed out by (Chambers 2016), everything that exists in R is an object. This includes objects that make things happen, such as language objects or functions, but also the more basic “things”, such as data objects. 24.1 Homogeneous vectors Data objects contain data, and possibly metadata. Data is always in the form of a vector, which can have different type. We can find the type by typeof, and vector length by length. Vectors are created by c, which combines individual elements: typeof(1:10) #&gt; [1] &quot;integer&quot; length(1:10) #&gt; [1] 10 typeof(1.0) #&gt; [1] &quot;double&quot; length(1.0) #&gt; [1] 1 typeof(c(&quot;foo&quot;, &quot;bar&quot;)) #&gt; [1] &quot;character&quot; length(c(&quot;foo&quot;, &quot;bar&quot;)) #&gt; [1] 2 typeof(c(TRUE, FALSE)) #&gt; [1] &quot;logical&quot; Vectors of this kind can only have a single type. Note that vectors can have length zero, e.g. in, i = integer(0) typeof(i) #&gt; [1] &quot;integer&quot; i #&gt; integer(0) length(i) #&gt; [1] 0 We can retrieve (or in assignments: replace) elements in a vector using [ or [[: a = c(1,2,3) a[2] #&gt; [1] 2 a[[2]] #&gt; [1] 2 a[2:3] #&gt; [1] 2 3 a[2:3] = c(5,6) a #&gt; [1] 1 5 6 a[[3]] = 10 a #&gt; [1] 1 5 10 where the difference is that [ can operate on an index range (or multiple indexes), and [[ operates on a single vector value. 24.2 Heterogeneous vectors: list An additional vector type is the list, which can combine any types in its elements: l &lt;- list(3, TRUE, &quot;foo&quot;) typeof(l) #&gt; [1] &quot;list&quot; length(l) #&gt; [1] 3 For lists, there is a further distinction between [ and [[: the single [ returns always a list, and [[ returns the contents of a list element: l[1] #&gt; [[1]] #&gt; [1] 3 l[[1]] #&gt; [1] 3 For replacement, one case use [ when providing a list, and [[ when providing a new value: l[1:2] = list(4, FALSE) l #&gt; [[1]] #&gt; [1] 4 #&gt; #&gt; [[2]] #&gt; [1] FALSE #&gt; #&gt; [[3]] #&gt; [1] &quot;foo&quot; l[[3]] = &quot;bar&quot; l #&gt; [[1]] #&gt; [1] 4 #&gt; #&gt; [[2]] #&gt; [1] FALSE #&gt; #&gt; [[3]] #&gt; [1] &quot;bar&quot; In case list elements are named, as in l = list(first = 3, second = TRUE, third = &quot;foo&quot;) l #&gt; $first #&gt; [1] 3 #&gt; #&gt; $second #&gt; [1] TRUE #&gt; #&gt; $third #&gt; [1] &quot;foo&quot; we can use names as in l[[&quot;second&quot;]] and this can be abbreviated to l$second #&gt; [1] TRUE l$second = FALSE l #&gt; $first #&gt; [1] 3 #&gt; #&gt; $second #&gt; [1] FALSE #&gt; #&gt; $third #&gt; [1] &quot;foo&quot; This is convenient, but also requires name look-up in the names attribute (see below). 24.2.1 NULL and removing list elements NULL is the null value in R; it is special in the sense that it doesn’t work in simple comparisons: 3 == NULL # not FALSE! #&gt; logical(0) NULL == NULL # not even TRUE! #&gt; logical(0) but has to be treated specially, using is.null: is.null(NULL) #&gt; [1] TRUE When we want to remove one or more list elements, we can do so by creating a new list that does not contain the elements that needed removal, as in l = l[c(1,3)] # remove second, implicitly l #&gt; $first #&gt; [1] 3 #&gt; #&gt; $third #&gt; [1] &quot;foo&quot; but we can also assign NULL to the element we want to eliminate: l$second = NULL l #&gt; $first #&gt; [1] 3 #&gt; #&gt; $third #&gt; [1] &quot;foo&quot; 24.3 Attributes We can glue arbitrary metadata objects to data objects, as in a = 1:3 attr(a, &quot;some_meta_data&quot;) = &quot;foo&quot; a #&gt; [1] 1 2 3 #&gt; attr(,&quot;some_meta_data&quot;) #&gt; [1] &quot;foo&quot; and this can be retrieved, or replaced by attr(a, &quot;some_meta_data&quot;) #&gt; [1] &quot;foo&quot; attr(a, &quot;some_meta_data&quot;) = &quot;bar&quot; attr(a, &quot;some_meta_data&quot;) #&gt; [1] &quot;bar&quot; In essence, the attribute of an object is a named list, and we can get or set the complete list by attributes(a) #&gt; $some_meta_data #&gt; [1] &quot;bar&quot; attributes(a) = list(some_meta_data = &quot;foo&quot;) attributes(a) #&gt; $some_meta_data #&gt; [1] &quot;foo&quot; A number of attributes are treated specially by R, see e.g. ?attributes. 24.3.1 object class and class attribute Every object in R “has a class”, meaning that class(obj) returns a character vector with the class of obj. Some objects have an implicit class, e.g. vectors class(1:3) #&gt; [1] &quot;integer&quot; class(c(TRUE, FALSE)) #&gt; [1] &quot;logical&quot; class(c(&quot;TRUE&quot;, &quot;FALSE&quot;)) #&gt; [1] &quot;character&quot; but we can also set the class explicit, either by using attr or by using class in the left-hand side of an expression: a = 1:3 class(a) = &quot;foo&quot; a #&gt; [1] 1 2 3 #&gt; attr(,&quot;class&quot;) #&gt; [1] &quot;foo&quot; class(a) #&gt; [1] &quot;foo&quot; attributes(a) #&gt; $class #&gt; [1] &quot;foo&quot; in which case the newly set class overrides the earlier implicit class. This way, we can add methods for class foo, e.g. by print.foo = function(x, ...) print(paste(&quot;an object of class foo with length&quot;, length(x))) print(a) #&gt; [1] &quot;an object of class foo with length 3&quot; Providing such methods are generally intended to create more usable software, but at the same time they may make the objects more opaque. It is sometimes useful to see what an object “is made of” by printing it after the class attribute is removed, as in unclass(a) #&gt; [1] 1 2 3 As a more elaborate example, consider the case where a polygon is made using package sf: library(sf) p = st_polygon(list(rbind(c(0,0), c(1,0), c(1,1), c(0,0)))) p #&gt; POLYGON ((0 0, 1 0, 1 1, 0 0)) which prints the well-known-text form; to understand what the data structure is like, we can use unclass(p) #&gt; [[1]] #&gt; [,1] [,2] #&gt; [1,] 0 0 #&gt; [2,] 1 0 #&gt; [3,] 1 1 #&gt; [4,] 0 0 24.3.2 the dim attribute The dim attribute sets the matrix or array dimensions: a = 1:8 class(a) #&gt; [1] &quot;integer&quot; attr(a, &quot;dim&quot;) = c(2,4) # or: dim(a) = c(2,4) class(a) #&gt; [1] &quot;matrix&quot; a #&gt; [,1] [,2] [,3] [,4] #&gt; [1,] 1 3 5 7 #&gt; [2,] 2 4 6 8 attr(a, &quot;dim&quot;) = c(2,2,2) # or: dim(a) = c(2,2,2) class(a) #&gt; [1] &quot;array&quot; a #&gt; , , 1 #&gt; #&gt; [,1] [,2] #&gt; [1,] 1 3 #&gt; [2,] 2 4 #&gt; #&gt; , , 2 #&gt; #&gt; [,1] [,2] #&gt; [1,] 5 7 #&gt; [2,] 6 8 24.4 various names attributes Named vectors carry their names in a names attribute. We saw examples for lists above, an example for a numeric vector is: a = c(first = 3, second = 4, last = 5) a[&quot;second&quot;] #&gt; second #&gt; 4 attributes(a) #&gt; $names #&gt; [1] &quot;first&quot; &quot;second&quot; &quot;last&quot; More name attributes are e.g. dimnames of matrices or arrays: a = matrix(1:4, 2, 2) dimnames(a) = list(rows = c(&quot;row1&quot;, &quot;row2&quot;), cols = c(&quot;col1&quot;, &quot;col2&quot;)) a #&gt; cols #&gt; rows col1 col2 #&gt; row1 1 3 #&gt; row2 2 4 attributes(a) #&gt; $dim #&gt; [1] 2 2 #&gt; #&gt; $dimnames #&gt; $dimnames$rows #&gt; [1] &quot;row1&quot; &quot;row2&quot; #&gt; #&gt; $dimnames$cols #&gt; [1] &quot;col1&quot; &quot;col2&quot; Data.frame objects have rows and columns, and each have names: df = data.frame(a = 1:3, b = c(TRUE, FALSE, TRUE)) attributes(df) #&gt; $names #&gt; [1] &quot;a&quot; &quot;b&quot; #&gt; #&gt; $row.names #&gt; [1] 1 2 3 #&gt; #&gt; $class #&gt; [1] &quot;data.frame&quot; 24.5 using structure When programming, the pattern of adding or modifying attributes before returning an object is extremely common, an example being: f = function(x) { a = create_obj(x) # call some other function attributes(a) = list(class = &quot;foo&quot;, meta = 33) a } The last two statements can be contracted in f = function(x) { a = create_obj(x) # call some other function structure(a, class = &quot;foo&quot;, meta = 33) } where function structure adds, replaces, or (in case of value NULL) removes attributes from the object in its first argument. References "],
["references.html", "References", " References "]
]
